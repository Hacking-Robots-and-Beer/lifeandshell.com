<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Lifeandshell, Code, Web on Cactus theme example</title>
    <link>http://localhost:1313/categories/lifeandshell-code-web/</link>
    <description>Recent content in Lifeandshell, Code, Web on Cactus theme example</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <copyright>You</copyright>
    <lastBuildDate>Fri, 06 Nov 2015 15:23:27 +0000</lastBuildDate>
    <atom:link href="http://localhost:1313/categories/lifeandshell-code-web/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Elasticsearch controller</title>
      <link>http://localhost:1313/posts/elasticsearch-controller/</link>
      <pubDate>Fri, 06 Nov 2015 15:23:27 +0000</pubDate>
      <guid>http://localhost:1313/posts/elasticsearch-controller/</guid>
      <description>&lt;p&gt;So we uses alot of easticsearch. And here is i small script to get status and do some simple task with es server.&lt;br /&gt;&#xA;You can get cluster status and cron for index deletions.&lt;/p&gt;&#xA;&lt;p&gt;&amp;nbsp;&lt;/p&gt;&#xA;&lt;pre&gt;import urllib2&#xD;&#xA;#&#xD;&#xA;#&#xD;&#xA;# Clean up elastich search index by removing old stuff.&#xD;&#xA;#The defult ip to es server&#xD;&#xA;dhost=&#39;10.101.1.31&#39;&#xD;&#xA;#The index name you are using&#xD;&#xA;index_name=&#39;logstash-syslog&#39;&#xD;&#xA;#Drop index back in time&#xD;&#xA;drop_index_back=90&#xD;&#xA;&#xD;&#xA;def date_back_in_time(days_back):&#xD;&#xA; &#39;&#39;&#39;&#xD;&#xA; Get the date back in time the days you send in&#xD;&#xA; &#39;&#39;&#39;&#xD;&#xA; import datetime as DT&#xD;&#xA; today = DT.date.today()&#xD;&#xA; back_in_time = today - DT.timedelta(days=days_back)&#xD;&#xA; return str(back_in_time).replace(&#39;-&#39;,&#39;.&#39;)&#xD;&#xA;&#xD;&#xA;def connect(hostname=dhost,command=&#39;_cluster/health&#39;,pretty=True,drop=False):&#xD;&#xA; &#39;&#39;&#39;&#xD;&#xA; Run the command against the es server&#xD;&#xA; &#39;&#39;&#39;&#xD;&#xA; if drop:&#xD;&#xA; print &#34;dropping index {0}&#34;.format(command)&#xD;&#xA; req = urllib2.Request(&#34;http://{0}:9200/{1}&#34;.format(hostname,command))&#xD;&#xA; req.get_method = lambda: &#39;DELETE&#39;&#xD;&#xA; else:&#xD;&#xA; if pretty: &#xD;&#xA; req = urllib2.Request(&#34;http://{0}:9200/{1}?pretty&#34;.format(hostname,command))&#xD;&#xA; else:&#xD;&#xA; req = urllib2.Request(&#34;http://{0}:9200/{1}&#34;.format(hostname,command))&#xD;&#xA;&#xD;&#xA;print req&#xD;&#xA; response = urllib2.urlopen(req)&#xD;&#xA; result = response.read()&#xD;&#xA; print result&#xD;&#xA;&#xD;&#xA;def check_cluster_status():&#xD;&#xA; &#39;&#39;&#39;&#xD;&#xA; Do some basic checks to get es cluster status&#xD;&#xA; &#39;&#39;&#39;&#xD;&#xA; connect(command=&#39;_cluster/health&#39;)&#xD;&#xA;&#xD;&#xA;def check_index_size():&#xD;&#xA; &#39;&#39;&#39;&#xD;&#xA; check the index stat&#xD;&#xA;&#xD;&#xA;us and size&#xD;&#xA;&#39;&#39;&#39;&#xD;&#xA;connect(command=&#39;_cat/indices?v&#39;)&#xD;&#xA;&#xD;&#xA;def check_index_status():&#xD;&#xA;&#39;&#39;&#39;&#xD;&#xA;check the index status and size&#xD;&#xA;&#39;&#39;&#39;&#xD;&#xA;connect(command=&#39;{0}-2015.10.17/_status&#39;.format(index_name))&#xD;&#xA;&#xD;&#xA;def check_es_recovery():&#xD;&#xA;&#39;&#39;&#39;&#xD;&#xA;check the index status and size&#xD;&#xA;&#39;&#39;&#39;&#xD;&#xA;connect(command=&#39;_recovery&#39;)&#xD;&#xA;&#xD;&#xA;def do_full_check():&#xD;&#xA;&#39;&#39;&#39;&#xD;&#xA;Rann all test &#xD;&#xA;&#39;&#39;&#39;&#xD;&#xA;&#xD;&#xA;check_cluster_status()&#xD;&#xA;check_index_size()&#xD;&#xA;check_index_status()&#xD;&#xA;check_es_recovery()&#xD;&#xA;&#xD;&#xA;def cron_drop_es_index():&#xD;&#xA;&#39;&#39;&#39;&#xD;&#xA;Drop is index 90 days back.&#xD;&#xA;This function get thte date 90 days back and drops that index&#xD;&#xA;This function should be run everyday to performe daly drops.&#xD;&#xA;IMPORTANT&#xD;&#xA;If you cange the number of days to drop run clean_out_es_index() to clean out all index between&#xD;&#xA;365 days and your drop date. &#xD;&#xA;&#39;&#39;&#39;&#xD;&#xA;drop = &#34;{0}-{1}/&#34;.format(index_name,date_back_in_time(drop_index_back))&#xD;&#xA;connect(command=drop,drop=True)&#xD;&#xA;&#xD;&#xA;def clean_out_es_index():&#xD;&#xA;&#39;&#39;&#39;&#xD;&#xA;Clean out index from 365 days and to the set drop_index_back value&#xD;&#xA;&#39;&#39;&#39;&#xD;&#xA;for x in range(drop_index_back,365):&#xD;&#xA;print date_back_in_time(x)&#xD;&#xA;&#xD;&#xA;&#xD;&#xA;if args.run == &#34;cron_drop_es_index&#34;:&#xD;&#xA; cron_drop_es_index()&#xD;&#xA;&#xD;&#xA;elif args.run == &#34;clean_out_es_index&#34;:&#xD;&#xA; clean_out_es_index()&#xD;&#xA;&#xD;&#xA;elif args.run == &#34;do_full_check&#34;:&#xD;&#xA; do_full_check()&#xD;&#xA;&#xD;&#xA;elif args.run == &#34;check_es_recovery&#34;:&#xD;&#xA; check_es_recovery()&#xD;&#xA;&#xD;&#xA;elif args.run == &#34;check_index_status&#34;:&#xD;&#xA; check_index_status()&#xD;&#xA;&#xD;&#xA;elif args.run == &#34;check_index_size&#34;:&#xD;&#xA; check_index_size()&#xD;&#xA;&#xD;&#xA;elif args.run == &#34;check_cluster_status&#34;:&#xD;&#xA; check_cluster_status()&#xD;&#xA;&#xD;&#xA;else:&#xD;&#xA; print &#34;Please enter i correct command &#34;&lt;/pre&gt;</description>
    </item>
  </channel>
</rss>
