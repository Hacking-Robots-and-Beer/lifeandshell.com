<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Code on Life and Shell</title>
    <link>https://lifeandshell.com/categories/code/</link>
    <description>Recent content in Code on Life and Shell</description>
    <generator>Hugo</generator>
    <language>en-us</language>
    <copyright>Mattias Hemmingssion mattias@lifeandshell.com</copyright>
    <lastBuildDate>Tue, 16 Sep 2025 09:59:24 +0000</lastBuildDate>
    <atom:link href="https://lifeandshell.com/categories/code/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>How to Automate LinkedIn Posts with Python 2025</title>
      <link>https://lifeandshell.com/posts/how-to-automate-linkedin-posts-with-python-the-2025-guide/</link>
      <pubDate>Tue, 16 Sep 2025 09:59:24 +0000</pubDate>
      <guid>https://lifeandshell.com/posts/how-to-automate-linkedin-posts-with-python-the-2025-guide/</guid>
      <description>I have a simple workflow: I write my posts in WordPress, and once they&amp;#8217;re ready, a workflow kicks off to get them published. A key part of this process is announcing the new post on LinkedIn to let my network know it&amp;#8217;s live.&#xA;Sounds easy, right? Well, I quickly discovered that most Python libraries for the LinkedIn API are outdated. LinkedIn has deprecated large parts of its old API, leaving many tools broken.</description>
    </item>
    <item>
      <title>Wazuh  Digest any source!</title>
      <link>https://lifeandshell.com/posts/wazuh-digest-any-source/</link>
      <pubDate>Sun, 13 Apr 2025 09:32:36 +0000</pubDate>
      <guid>https://lifeandshell.com/posts/wazuh-digest-any-source/</guid>
      <description>How I Built a Custom Wazuh Log Ingest Pipeline (And Ditched the Wodle) If you&amp;#8217;ve ever tried to push custom logs into Wazuh, youâ€™ve probably stumbled across something called a Wodle. Wazuh uses these built-in scripts to collect and parse dataâ€”especially useful for integrations like AWS.&#xA;Soâ€¦ Wodle for AWS? Sure, Wodle can collect AWS logs. But when I tried using it for my AWS environment, things didnâ€™t exactly go as planned.</description>
    </item>
    <item>
      <title>k3s Cluster on setup master and node</title>
      <link>https://lifeandshell.com/posts/k3s-cluster-on-setup-master-and-node/</link>
      <pubDate>Sat, 07 Jan 2023 11:31:43 +0000</pubDate>
      <guid>https://lifeandshell.com/posts/k3s-cluster-on-setup-master-and-node/</guid>
      <description>For some IoT setups a need a k3s cluster running. To make it spread and to add more nodes a installed the k3s Master on my firewall running a small atom processor. But wanted to run the nodes on raspberry or rock nodes to handle the load.&#xA;Then by using labels on nodes I want to apply different workloads on the nodes.&#xA;Pre So before installing k3s master. I had my pihole running on port 80 and that did not work that well.</description>
    </item>
    <item>
      <title>Device Tracker using Dhpcd server and bash</title>
      <link>https://lifeandshell.com/posts/device-tracker-using-dhpcd-server-and-bash/</link>
      <pubDate>Wed, 21 Dec 2022 14:07:01 +0000</pubDate>
      <guid>https://lifeandshell.com/posts/device-tracker-using-dhpcd-server-and-bash/</guid>
      <description>I have used Home Assistance for some time. And have always used the device tracker to set different actions based if I&amp;#8217;m home or not.&#xA;But when my pfsense died and a install a clean Linux box as my fw and DHCP server I lost all my tracking for devices.&#xA;But I did found out that the dhcpd server can run a command every time it hands out a dhcpds leese.</description>
    </item>
    <item>
      <title>Migrate Elasticsearch helm to Elasticsearch Operator</title>
      <link>https://lifeandshell.com/posts/migrate-elasticsearch-helm-to-elasticsearch-operator/</link>
      <pubDate>Thu, 01 Dec 2022 13:17:35 +0000</pubDate>
      <guid>https://lifeandshell.com/posts/migrate-elasticsearch-helm-to-elasticsearch-operator/</guid>
      <description>Migrate elasticsearch helm to elasticsearch operator and from version 7 to version 8.&#xA;So in the start, I used the helm chart for elasticsearch, and everything worked fine. Then elasticsearch 8 comes and the Elasticsearch operator.&#xA;This broke by helm chart and kind of left me in a stalled state.&#xA;But now I have to migrate my current elasticsearch that uses a helm chart to start using the operator.</description>
    </item>
    <item>
      <title>Openstreat map Docker och docker compose</title>
      <link>https://lifeandshell.com/posts/openstreat-map-docker-och-docker-compose/</link>
      <pubDate>Thu, 17 Nov 2022 16:53:00 +0000</pubDate>
      <guid>https://lifeandshell.com/posts/openstreat-map-docker-och-docker-compose/</guid>
      <description>Split up in separate containers !&#xA;Running openstreetmap map in docker was hard. And the docs all wanted to run it bounded with postgress and not in separate containers.&#xA;I setup so we can run osm I different containers for you to scale&#xA;https://github.com/mattiashem/osm&#xA;Clone this GitHub repo and then start it with&#xA;docker compose build&#xA;then to start it, run docker compose up&#xA;What is happening First we are building a custom Postgres docker image.</description>
    </item>
    <item>
      <title>kubernetes update 1.22 -&gt;1.23 Helm Error</title>
      <link>https://lifeandshell.com/posts/kubernetes-update-1-22-1-23-helm-error/</link>
      <pubDate>Thu, 15 Sep 2022 16:02:06 +0000</pubDate>
      <guid>https://lifeandshell.com/posts/kubernetes-update-1-22-1-23-helm-error/</guid>
      <description>I was in the progress of updating my cluster and in version 1.23 we have breaking changes.&#xA;What I did not know was that helm saves the latest deployed version in secret.&#xA;So I updated the cluster to version 1.23 and started getting helm errors.&#xA;And it does not matter if I delete the resources in the cluster. The issue is that helm has saved the last deployment with a API version that with the new k8s version is no longer supported.</description>
    </item>
    <item>
      <title>Elasticsearch controller</title>
      <link>https://lifeandshell.com/posts/elasticsearch-controller/</link>
      <pubDate>Fri, 06 Nov 2015 15:23:27 +0000</pubDate>
      <guid>https://lifeandshell.com/posts/elasticsearch-controller/</guid>
      <description>So we uses alot of easticsearch. And here is i small script to get status and do some simple task with es server.&#xA;You can get cluster status and cron for index deletions.&#xA;&amp;nbsp;&#xA;import urllib2&#xD;#&#xD;#&#xD;# Clean up elastich search index by removing old stuff.&#xD;#The defult ip to es server&#xD;dhost=&#39;10.101.1.31&#39;&#xD;#The index name you are using&#xD;index_name=&#39;logstash-syslog&#39;&#xD;#Drop index back in time&#xD;drop_index_back=90&#xD;def date_back_in_time(days_back):&#xD;&#39;&#39;&#39;&#xD;Get the date back in time the days you send in&#xD;&#39;&#39;&#39;&#xD;import datetime as DT&#xD;today = DT.</description>
    </item>
    <item>
      <title>Python DOS protection (iptables,dos)</title>
      <link>https://lifeandshell.com/posts/python-dos-protection-iptablesdos/</link>
      <pubDate>Fri, 06 Nov 2015 15:18:51 +0000</pubDate>
      <guid>https://lifeandshell.com/posts/python-dos-protection-iptablesdos/</guid>
      <description>here are a small script I use to have some sort of dos protection on my webservers.&#xA;&amp;nbsp;&#xA;import subprocess&#xD;whitelist=[&#39;192.168.1.2&#39;]&#xD;blockvalue=2&#xD;alertvalue=1&#xD;proc = subprocess.Popen(&#34;netstat -ntu | awk &#39;{print $5}&#39; | cut -d: -f1 | sort | uniq -c | sort -n&#34;, shell=True,stdout=subprocess.PIPE)&#xD;running = proc.stdout.read()&#xD;runing_sorted = running.split(&#39;\n&#39;)&#xD;for r in runing_sorted:&#xD;con =r.split()&#xD;if len(con) ==2:&#xD;#If ip has more conenctions then block value ip block&#xD;if con[0] &amp;lt;= blockvalue:&#xD;print &#34;</description>
    </item>
    <item>
      <title>Raspberry pi And Tellusd</title>
      <link>https://lifeandshell.com/posts/raspberry-pi-and-tellusd/</link>
      <pubDate>Mon, 20 Apr 2015 09:24:02 +0000</pubDate>
      <guid>https://lifeandshell.com/posts/raspberry-pi-and-tellusd/</guid>
      <description>Im using tellus to get info from my sensors like huminity and temp.&#xA;And to get to work am using my rasp pi to recive and send siganls.&#xA;Here is a quick guide to install and setup tellusd on you raspberry.&#xA;&amp;nbsp;&#xA;1. Verify that tellus is there pi@raspberrypi ~ $ lsusb&#xD;Bus 001 Device 002: ID 0424:9512 Standard Microsystems Corp. Bus 001 Device 001: ID 1d6b:0002 Linux Foundation 2.0 root hub&#xD;Bus 001 Device 003: ID 0424:ec00 Standard Microsystems Corp.</description>
    </item>
    <item>
      <title>Setup SPI on Raspberry pi (mcp3008, Adafruit)</title>
      <link>https://lifeandshell.com/posts/setup-spi-on-raspberry-pi-mcp3008-adafruit/</link>
      <pubDate>Sun, 19 Apr 2015 20:25:33 +0000</pubDate>
      <guid>https://lifeandshell.com/posts/setup-spi-on-raspberry-pi-mcp3008-adafruit/</guid>
      <description>Im building my own watering system and to that I will have some sensores..&#xA;They are connected to my pi over SFI and a mcp3008 from Adafruit.&#xA;&amp;nbsp;&#xA;The gear http://www.adafruit.com/products/1989&#xA;http://www.adafruit.com/products/856&#xA;http://www.kjell.com/sortiment/el/elektronik/elektroniklab/kopplingsplatta-lodfri-p87886&#xA;http://www.elecfreaks.com/store/octopus-soil-moisture-sensor-brick-p-422.html&#xA;&amp;nbsp;&#xA;Setup the cables Use this guide and se how the you should connect the mcp3008 and the sensore.&#xA;http://www.raspberrypi-spy.co.uk/2013/10/analogue-sensors-on-the-raspberry-pi-using-an-mcp3008/&#xA;&amp;nbsp;&#xA;Get the Pi ready &amp;nbsp;&#xA;1. First enable SFI on the board here&#xA;http://www.raspberrypi-spy.co.uk/2014/08/enabling-the-spi-interface-on-the-raspberry-pi/&#xA;I uses the raspi-config and enabled the SFI</description>
    </item>
    <item>
      <title>Installing Go build server on centos 7</title>
      <link>https://lifeandshell.com/posts/installing-go-build-server-on-centos-7/</link>
      <pubDate>Wed, 11 Feb 2015 21:39:35 +0000</pubDate>
      <guid>https://lifeandshell.com/posts/installing-go-build-server-on-centos-7/</guid>
      <description>Installing the go build server in centos 7 with some easy step&#xA;&amp;nbsp;&#xA;&amp;nbsp;&#xA;1. First head over to the go page and have a look around http://www.go.cd/&#xA;2. Download go server to you centos box &amp;nbsp;&#xA;wget http://download.go.cd/gocd-rpm/go-server-14.4.0-1356.noarch.rpm&#xD;wgetÂ http://download.go.cd/gocd-rpm/go-agent-14.4.0-1356.noarch.rpm 3. Install it First start by adding the go user (something broken in install)&#xA;useradd go Now run yum localinstall to install local packages&#xA;yum installÂ java-1.7.0-openjdk -y&#xD;yum localinstall go-server-14.</description>
    </item>
    <item>
      <title>Getting django docker prod ready with jenkins (part 1 the build)</title>
      <link>https://lifeandshell.com/posts/getting-django-docker-prod-ready-with-jenkins-part-1-the-build/</link>
      <pubDate>Sun, 18 Jan 2015 21:25:59 +0000</pubDate>
      <guid>https://lifeandshell.com/posts/getting-django-docker-prod-ready-with-jenkins-part-1-the-build/</guid>
      <description>So i have some django webb projects and now its time to get my django apps prod ready with docker.&#xA;My plan is to with jenkins build my django apps (soon start a docker of the app and run some test but that will be later) make a docker image and send that to the docker cloud.&#xA;Then a can download the docker image on my prod server and start the app.</description>
    </item>
    <item>
      <title>vmware to kvm (OWASP broken webb app on KVM)</title>
      <link>https://lifeandshell.com/posts/vmware-to-kvm-owasp-broken-webb-app-on-kvm/</link>
      <pubDate>Tue, 09 Sep 2014 10:38:29 +0000</pubDate>
      <guid>https://lifeandshell.com/posts/vmware-to-kvm-owasp-broken-webb-app-on-kvm/</guid>
      <description>So I uses kvm for my virtual server. But i got OWASP broken webb app in vmware format and its not ok.&#xA;But with the help from google i found some help to get the OWASP Broken Webb App on my kvm hosts.&#xA;I follewed the info from this page&#xA;&amp;nbsp;&#xA;http://blog.bodhizazen.net/linux/convert-vmware-vmdk-to-kvm-qcow2-or-virtualbox-vdi/&#xA;&amp;nbsp;&#xA;&amp;nbsp;&#xA;1. Download and unzip Owasp Broken Webb app to you folder (It uses 7zip for some reason) https://www.</description>
    </item>
    <item>
      <title>OAuth2 Server on Python (with flask on Centos)</title>
      <link>https://lifeandshell.com/posts/oauth2-server-on-python-with-flask-on-centos/</link>
      <pubDate>Fri, 30 May 2014 20:04:05 +0000</pubDate>
      <guid>https://lifeandshell.com/posts/oauth2-server-on-python-with-flask-on-centos/</guid>
      <description>So at work we have started to look at OAuth2 for our web apps. So on our creativ friday today i started looking at putting together an OAuth2 server using python and flask.&#xA;I followed the guide from this pageÂ http://lepture.com/en/2013/create-oauth-server&#xA;And after some work I got an working server and client running on my Centos server.&#xA;The code only uses an sqlite db and are only testing the OAuth functions so for a working solutions there are some more work.</description>
    </item>
    <item>
      <title>Starting with Go on Ubuntu</title>
      <link>https://lifeandshell.com/posts/starting-with-go-on-ubuntu/</link>
      <pubDate>Sat, 24 May 2014 20:56:02 +0000</pubDate>
      <guid>https://lifeandshell.com/posts/starting-with-go-on-ubuntu/</guid>
      <description>So I starting to test to use the go language for some projects. Here is how i set up go on my ubuntu laptop.&#xA;&amp;nbsp;&#xA;1. Installing go language sudo apt-get install python-software-properties sudo add-apt-repository ppa:duh/golang&#xD;sudo apt-get update&#xD;sudo apt-get install golang verify&#xA;go version 2. Getting an good IDE I uses sublime text find if here and install it&#xA;http://www.sublimetext.com/&#xA;3. Write you first line of code in GO Start up an new file in sublime and past this in the file (I call the file main.</description>
    </item>
    <item>
      <title>Build you first syco Module</title>
      <link>https://lifeandshell.com/posts/build-you-first-syco-module/</link>
      <pubDate>Tue, 18 Feb 2014 22:12:56 +0000</pubDate>
      <guid>https://lifeandshell.com/posts/build-you-first-syco-module/</guid>
      <description>SO from the last post you can install syco but you also need to build and update your own plugins in syco.&#xA;Here is a small guide how to build you first plugin.&#xA;Here om building some syco commands for controlling apache and glassfish server.&#xA;the commands are run from our syco-chuck release commands center so for adding them to syco i can controll the script from sudo and do some extra test before starting and stopping the service.</description>
    </item>
    <item>
      <title>Setup SYCO on you centos box</title>
      <link>https://lifeandshell.com/posts/setup-syco-on-you-centos-box/</link>
      <pubDate>Tue, 18 Feb 2014 15:27:04 +0000</pubDate>
      <guid>https://lifeandshell.com/posts/setup-syco-on-you-centos-box/</guid>
      <description>So if you care about security and stability you must have syco installed on your server.&#xA;Read more about syco on the github projectÂ https://github.com/systemconsole&#xA;Im staring to use syco not only production but also on my &amp;#8220;Own&amp;#8221; server.&#xA;So more of you should really start using it and here is i guide for you to start using syco&#xA;1. Installing and setting up centos yum install git &amp;nbsp;&#xA;Gettings syco</description>
    </item>
    <item>
      <title>Installing Asylguiden on centos Server</title>
      <link>https://lifeandshell.com/posts/installing-asylguiden-on-centos-server/</link>
      <pubDate>Mon, 17 Feb 2014 21:21:20 +0000</pubDate>
      <guid>https://lifeandshell.com/posts/installing-asylguiden-on-centos-server/</guid>
      <description>One of my own prodjects are Asylguiden. Its A python publish system build with django, Mysql and mongodb.&#xA;You can find the code here on github&#xA;https://github.com/mattiashem/asylguiden&#xA;Asylguiden also works with wsgi for python and apache for displaying content&#xA;here is my own how to for downloadning and setting up asylguiden on a production server.&#xA;1. Setting up server for hosing Centos&#xA;yum install httpd mod_ssl git wget python-setuptools mod_wsgi &amp;nbsp;</description>
    </item>
    <item>
      <title>ejabber users from postfixadmin (python,mysql,md5crypt)</title>
      <link>https://lifeandshell.com/posts/ejabber-users-from-postfixadmin-pythonmysqlmd5crypt/</link>
      <pubDate>Fri, 10 Jan 2014 21:28:51 +0000</pubDate>
      <guid>https://lifeandshell.com/posts/ejabber-users-from-postfixadmin-pythonmysqlmd5crypt/</guid>
      <description>So Im running my emails with postfix and have postfix admin to manager my users and domains. But now it should be nice to have i jabber server running and to have the same user and password for both email and jabber.&#xA;Ejabber support custom auth plugins and with some python i now have a working plugin.&#xA;&amp;nbsp;&#xA;First install python packages yum install MySQL-python&#xD;yum install python-passlib &amp;nbsp;&#xA;Add this script to you ejabber folder</description>
    </item>
    <item>
      <title>Install and setup Haystack search for Django</title>
      <link>https://lifeandshell.com/posts/install-and-setup-haystack-search-for-django/</link>
      <pubDate>Sun, 05 Jan 2014 22:28:01 +0000</pubDate>
      <guid>https://lifeandshell.com/posts/install-and-setup-haystack-search-for-django/</guid>
      <description>So Mysql is crap at doing full text search. So in one of my projects i use Haystack so i can do full text searches.&#xA;I have a running Django project up and this is how I setup haystack for my project.&#xA;&amp;nbsp;&#xA;Install and config sudo pip install django-haystack &amp;nbsp;&#xA;in settings.py under INSTALLED_APPS add haystack&#xA;&#39;haystack&#39;, &amp;nbsp;&#xA;And also in settings.py file add some haystack settings&#xA;import os&#xD;HAYSTACK_CONNECTIONS = {&#xD;&#39;default&#39;: {&#xD;&#39;ENGINE&#39;: &#39;haystack.</description>
    </item>
    <item>
      <title>Custom nagios plugins in python</title>
      <link>https://lifeandshell.com/posts/custom-nagios-plugins-in-python/</link>
      <pubDate>Tue, 05 Nov 2013 15:20:51 +0000</pubDate>
      <guid>https://lifeandshell.com/posts/custom-nagios-plugins-in-python/</guid>
      <description>For monitoring different service and function you may need to build some custom monitoring plugins. I have some build for nrpe and will work with both nagios and icinga.&#xA;This script will do and mysql check and then send the data back and also start graphing the data back if you use pnp4nagios ðŸ™‚&#xA;Every plugin must have two things.&#xA;1. an exit code thet will say the state of the plugin (OK.</description>
    </item>
    <item>
      <title>Install Bitsync on Raspberry Pi</title>
      <link>https://lifeandshell.com/posts/install-bitsync-on-raspberry-pi/</link>
      <pubDate>Fri, 13 Sep 2013 19:50:03 +0000</pubDate>
      <guid>https://lifeandshell.com/posts/install-bitsync-on-raspberry-pi/</guid>
      <description>So today im using dropbox to sync all my stuff between devices. But now there are so much there so my free space is almost full. So now its time for me to move to bitsync an then sync all my devices.&#xA;Install bitsync&#xA;Go to folder /opt&#xA;cd /opt Download bitsync&#xA;wget &#34;http://btsync.s3-website-us-east-1.amazonaws.com/btsync_arm.tar.gz&#34; unpack it&#xA;chmod 700Â btsync_arm.tar.gz&#xD;tarr zxvfÂ btsync_arm.tar.gz Start it&#xA;cd bitsync&#xD;./bitsync go to the webbpage</description>
    </item>
    <item>
      <title>Python ConfigParser using you own config files in python</title>
      <link>https://lifeandshell.com/posts/python-configparser-using-you-own-config-files-in-python/</link>
      <pubDate>Wed, 07 Aug 2013 11:26:42 +0000</pubDate>
      <guid>https://lifeandshell.com/posts/python-configparser-using-you-own-config-files-in-python/</guid>
      <description>Storing settings in config files and then let python read the configfiles and to good stuff .&#xA;&amp;nbsp;&#xA;Read the file&#xA;#Reading config file&#xD;config = ConfigParser.ConfigParser()&#xD;config.read(&#39;setting.cfg&#39;) print all items and values in an section&#xA;for name, value in config.items(&#34;monitor&#34;):&#xD;print &#39; %s = %s&#39; % (name, value) Print all items in configfile&#xA;for section_name in parser.sections():&#xD;print &#39;Section:&#39;, section_name&#xD;print &#39; Options:&#39;, parser.options(section_name)&#xD;for name, value in parser.items(section_name):&#xD;print &#39; %s = %s&#39; % (name, value) My settings.</description>
    </item>
    <item>
      <title>How the HELL is oncall ? (the oncall reminder script)</title>
      <link>https://lifeandshell.com/posts/how-the-hell-is-oncall-the-oncall-reminder-script/</link>
      <pubDate>Mon, 05 Aug 2013 21:59:17 +0000</pubDate>
      <guid>https://lifeandshell.com/posts/how-the-hell-is-oncall-the-oncall-reminder-script/</guid>
      <description>When you have oncall often sometimes is easy to forget hows oncall and when you are not. So for the last time wonder how is oncall and ask some python for some help,&#xA;&amp;nbsp;&#xA;The script&#xA;#!/usr/bin/env python&#xD;#&#xD;# Mattias Hemmingsson&#xD;# matte@elino.se&#xD;#&#xD;# Script for reminder friend when to bet&#xD;# Uses and csv file and send email to remind when its time to bet.&#xD;#&#xD;# import csv&#xD;import smtplib&#xD;from datetime import datetime, timedelta, date #Get users and send email to users&#xD;sender = &#39;noreply@elino.</description>
    </item>
    <item>
      <title>Extracting HP-Switch running config</title>
      <link>https://lifeandshell.com/posts/extracting-hp-switch-running-config/</link>
      <pubDate>Mon, 10 Jun 2013 15:29:02 +0000</pubDate>
      <guid>https://lifeandshell.com/posts/extracting-hp-switch-running-config/</guid>
      <description>Every so othen I have to extract my running-config from my hp switches. And put them under OSSEC file monitoring. And to verify so that no changes has bean done to the original running-config.&#xA;So here is an small script for extracting my running-config and mf5 check that they are the same as my standard config.&#xA;&amp;nbsp;&#xA;Make you own changes to the script to work in you system ðŸ™‚</description>
    </item>
    <item>
      <title>Django sending email</title>
      <link>https://lifeandshell.com/posts/django-sending-email/</link>
      <pubDate>Tue, 04 Jun 2013 21:35:24 +0000</pubDate>
      <guid>https://lifeandshell.com/posts/django-sending-email/</guid>
      <description>building and small webpage and in that page I want an small contact field. So my visitors (if any ) can contact me with an form input.&#xA;So I made an small html template that has a very small form (No validation ) and then post the email and massages back to the view that send the email.&#xA;small andÂ simpleÂ andÂ todayÂ work in front of the tv.&#xA;django template my template extends my index as you see called contact.</description>
    </item>
    <item>
      <title>Testing OSSEC / Syslog auth</title>
      <link>https://lifeandshell.com/posts/testing-ossec-syslog-auth/</link>
      <pubDate>Mon, 03 Jun 2013 20:38:35 +0000</pubDate>
      <guid>https://lifeandshell.com/posts/testing-ossec-syslog-auth/</guid>
      <description>Im runing and PCI DSS Level 1 system. And during our PCI Audit i have to provide evidence that our monitoring system (OSSEC) can log logins that fails.&#xA;So or testing this and to provide evidence for our audit I made a small python script.&#xA;the Scripts tries to login to th host specified in and text field and tries to run an command on them. (You can alter this to the correct username / password and then run commands on all server)</description>
    </item>
  </channel>
</rss>
